# 数据处理

## `已审核`1.问题：fluid 如何获取特定层的参数

+ 版本号：`1.1.0`

+ 标签：`模型参数`

+ 问题描述：在训练好一个模型之后，想打印模型的参数类似TF里面，w = session.run([fc1.W])
然后直接获取到了第一层FClayer的W矩阵，fluid有类似的接口吗？

+ 报错输出：

```
Traceback (most recent call last):
  File "test.py", line 12, in <module>
    ret = scope.find_var("target_fc").get_tensor()
AttributeError: 'NoneType' object has no attribute 'get_tensor'
```

+ 问题复现：

```python
import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr
x = fluid.layers.data(name='x', shape=[5], dtype='float32'),                          
param_attr = ParamAttr(name='target_fc')
bias_attr = ParamAttr(name='target_fc_b')
fc1 = fluid.layers.fc(input=x, size=128, act='relu', param_attr=param_attr, bias_attr=bias_attr)
scope = fluid.executor.global_scope()

# get tensor
ret = scope.find_var("target_fc").get_tensor()
print(ret)            
place = fluid.CPUPlace()
exe = fluid.Executor(place)
exe.run(fluid.default_startup_program())
```


+ 问题分析：

在PaddlePaddle中，program程序没有运行是，数据是不会进行初始化的，所以要将获得数据的操作diam放在运行逻辑之后，具体而言就是将`ret = scope.find_var("target_fc").get_tensor()`移动到`exe.run(fluid.default_startup_program())`之后

+ 解决方法：

```python
import paddle.fluid as fluid
from paddle.fluid.param_attr import ParamAttr
x = fluid.layers.data(name='x', shape=[5], dtype='float32'),                          
param_attr = ParamAttr(name='target_fc')
bias_attr = ParamAttr(name='target_fc_b')
fc1 = fluid.layers.fc(input=x, size=128, act='relu', param_attr=param_attr, bias_attr=bias_attr)

# get tensor
place = fluid.CPUPlace()
exe = fluid.Executor(place)
exe.run(fluid.default_startup_program())
ret = fluid.global_scope().find_var("target_fc").get_tensor()
import numpy as np
ret = np.array(ret)
print (ret.shape)
print(ret)
```

## `已审核`2.问题：fliud如何给指定的tensor赋值

+ 版本号：`1.1.0`

+ 标签：`tensor赋值`

+ 问题描述：现在想将tensorflow的权重转成fluid接口的权重，对应的tensor是否可以直接转换？在代码中，fliud如何给指定的tensor赋值？

+ 问题分析：所谓的权重，其本质就是一个矩阵，该矩阵在训练神经网络时获得，在TensorFlow中通常会将训练完的节点权重矩阵以文件的信息保存，因为tensorflow保存模型的文件格式与PaddlePaddle的存在差异，所以目前是无法直接将tensorFlow保存的模型文件直接导入。但理论上依旧可以将TensorFLow文件中的权重矩阵转到Fluid对应的接口上，需要手动操作。

+ 解决方法：

在Fluid中，可以手动的为tensor赋值，实例代码如下：

```python
import paddle.fluid as fluid
import numpy as np

np_data = np.random.uniform(0.1, 1, [3, 512, 512])
a = fluid.global_scope().find_var('var_a').get_tensor()
a.set(np_data)
```

上述代码会获得网络结构中名为var_a的节点，然后手动为该接口对应的tensor赋值。

更多细节可以参考：
https://github.com/PaddlePaddle/Paddle/blob/038e2817f0208f8de3761854700ff01fc5c28362/python/paddle/fluid/tests/book/test_label_semantic_roles.py#L178-L182

+ 问题拓展：
不只是TensorFlow中模型的节点的权重转为PaddlePaddle中模型节点的参数，对于任意框架，只要提供了手动设置节点参数值的方法都可以实现使用不同框架实现的模型的参数权重的转移，一个常规的思路就是先使用该模块对应的原框架将模型权重矩阵文件读入并通过numpy写成常规的numpy文件，在使用另外一个框架，如PaddlePaddle框架，将numpy文件读入，再使用相应的赋值方法将神经网络结构中节点的参数手动赋值，达到模型参数在不同框架间的转移。

## `已审核`3.问题：输入数据不指定尺寸

+ 版本号：`1.1.0`

+ 标签：`数据尺寸`

+ 问题描述：PaddlePaddle的Fluid版输入数据是否可以不指定尺寸，或者实际输入图像跟所指定尺寸不一样？

+ 报错输出：

```
Traceback (most recent call last):
  File "/Users/jizhi/Desktop/Paddle/Paddlecode/test.py", line 4, in <module>
    images = fluid.layers.data(name='pixel', shape=None, dtype='float32')
  File "/Users/jizhi/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layers/io.py", line 77, in data
    shape = list(shape)
TypeError: 'NoneType' object is not iterable
```

+ 问题复现：

```
import paddle.fluid as fluid
import numpy as np

images = fluid.layers.data(name='pixel', shape=None, dtype='float32')
```

+ 问题分析：

在PaddlePaddle中，data layer是必须指定shape尺寸的，但实际输入叙事指定尺寸可以不一样，如果data layer没有定义shape，则会报出`'NoneType' object is not iterable`

+ 问题解答：

使用fluid.lyaers.data()方法时需要指定shape参数

```
images = fluid.layers.data(name='images', shape=[3, 32, 32], dtype='float32')
```


+ 问题拓展：

data layer中shape是必须添加的，可以从PaddlePaddle的data()方法代码看出这一样要求。

```
def data(name,
         shape,
         append_batch_size=True,
         dtype='float32',
         lod_level=0,
         type=core.VarDesc.VarType.LOD_TENSOR,
         stop_gradient=True):
    helper = LayerHelper('data', **locals())
    shape = list(shape)
    for i in six.moves.range(len(shape)):
        if shape[i] is None:
            shape[i] = -1
            append_batch_size = False
        elif shape[i] < 0:
            append_batch_size = False

    if append_batch_size:
        shape = [-1] + shape  # append batch size as -1

    data_var = helper.create_global_variable(
        name=name,
        shape=shape,
        dtype=dtype,
        type=type,
        stop_gradient=stop_gradient,
        lod_level=lod_level,
        is_data=True)
    return data_var
```

从data()方法的代码中可以看出，如果shape中没有定义batch，会自动设置为-1。

## `已审核`4.问题：fluid版本如何做计算并打印出来

+ 版本号：`1.1.0`

+ 标签：`打印流程`

+ 问题描述：我使用Fluid版的PaddlePaddle编写了一段简单的加法计算代码，此时想要获得加法计算的结果，不需要张量本身的信息，但得到`sum() takes 1 positional argument but 2 were given`报错


+ 报错输出：

```
Traceback (most recent call last):
  File "/Users/jizhi/Desktop/Paddle/Paddlecode/test.py", line 7, in <module>
    c = fluid.layers.sum(a,b)
TypeError: sum() takes 1 positional argument but 2 were given
```

+ 问题复现：

```python
# coding=utf-8
import paddle.fluid as fluid

# 创建两常量
a = fluid.layers.fill_constant(shape=[2, 3], dtype="float32", value=1.0)
b = fluid.layers.fill_constant(shape=[2, 3], dtype="float32", value=1.0)

# 加法计算
c = fluid.layers.sum(a, b)

# 转换为打印信息
c_ = fluid.layers.Print(c)
print(c_)
```

+ 问题分析：
PaddlePaddle是执行与模型设计分离的，即使用python编写的只是定义了模型的结构，但并不会真正的运行，如果要获得对应的值，要先定义执行器，然后将最后要获得的结果传入执行器，让执行器依旧模型的结构执行。

而这里的报错原因是因为fluid.layers.sum()方法使用错误，这种风格的写法是TensorFlow的写法，而PaddlePaddle的加法操作的写法与之不同。

+ 解决方法：

修改fluid.layers.sum()方法的使用方式，并添加相应的执行器exe，运行执行器则可以获得结果。

```
import paddle.fluid as fluid

a = fluid.layers.fill_constant(shape=[2,3], dtype='float32', value=1.0)
b = fluid.layers.fill_constant(shape=[2,3], dtype='float32', value=1.0)

c = fluid.layers.sum(x=[a,b])
exe = fluid.Executor(fluid.CPUPlace())
exe.run(fluid.default_startup_program())
out = exe.run(fluid.default_main_program(), fetch_list=[c])
print(out)
```



更多细节可以参考PaddlePaddle API文档：http://www.paddlepaddle.org/documentation/api/en/1.1/layers.html

## `已审核`5.问题：如何使用numpy数组对Variable赋值？

+ 版本号：`1.1.0`

+ 标签：`使用numpy进行赋值`

+ 问题描述：
我使用fluid构造了一个网络模型，如：
conv1 = fluid.layers.conv2d(X, 64, 9,act='relu', name='conv1' ,
param_attr= fluid.ParamAttr(name='conv1_w'))
然后获取variable:
conv1_w = fluid.get_var('conv1_w')
我希望使用numpy数组对这个参数进行赋值，要如何做呢？

我查到资料说，可以使用 paddle.parameters.Parameters.set 进行赋值。但是我使用fluid.get_var获取到的对象不是paddle.parameters.Parameters类型的，没有set方法…

+ 问题解答：

Fluid中，为Variable赋值的方法如下，主要逻辑就是fluid.global_scope().find_var()找到模型结构中对应节点，然后通过get_tensor()方法获得对应的tensor对象，接着就可以使用set()方法对其进行赋值

```
 embedding_param = fluid.global_scope().find_var( 
     embedding_name).get_tensor() 
 embedding_param.set( 
     load_parameter(conll05.get_embedding(), word_dict_len, word_dim), 
     place) 
```

具体细节请参考：https://github.com/PaddlePaddle/Paddle/blob/038e2817f0208f8de3761854700ff01fc5c28362/python/paddle/fluid/tests/book/test_label_semantic_roles.py#L178-L182


## `已审核`6.问题：如何在两个program之间copy参数

+ 版本号：`1.1.0`

+ 标签：`参数复制`

+ 问题描述：在Fluid版本的PaddlePaddle中，如何实现在两个program之间copy参数？我通过下面代码尝试在两个program之间copy参数，但并没有骑到作用。

+ 问题复现：

```
import paddle.fluid as fluid
from rllab import lab
from rllab.utils import logger
import numpy as np

x = lab.data(name='x', shape=[5], dtype='float32')

policy_program = fluid.default_main_program().clone()
with fluid.program_guard(policy_program):
    with lab.variable_scope('policy'):
        y1 = lab.FullyConnected('fc', x, 10)

    vars = fluid.default_main_program().list_vars()
    policy_vars = filter(lambda x: 'GRAD' not in x.name and 'policy' in x.name, vars)
    for each in policy_vars:
        logger.info(each.name)

value_program = fluid.default_main_program().clone()
with fluid.program_guard(value_program):
    with lab.variable_scope('value'):
        y2 = lab.FullyConnected('fc', x, 10)
    vars = fluid.default_main_program().list_vars()
    value_vars = filter(lambda x: 'GRAD' not in x.name and 'value' in x.name, vars)


policy_vars.sort(key=lambda x:x.name)
value_vars.sort(key=lambda x:x.name)
sync_program = fluid.default_main_program().clone()
with fluid.program_guard(sync_program):
    sync_ops = []
    for i, var in enumerate(policy_vars):
        logger.info("[assign] policy:{}   value:{}".format(policy_vars[i].name, value_vars[i].name))
        sync_op = lab.assign(policy_vars[i], value_vars[i])
        sync_ops.append(sync_op)
    sync_program = sync_program.prune(sync_ops)

exe = fluid.Executor(fluid.CPUPlace())
exe.run(fluid.default_startup_program())
w0 = fluid.global_scope().find_var("policy/fc_W").get_tensor()
w1 = fluid.global_scope().find_var("value/fc_W").get_tensor()
print np.sum(np.array(w0))
print np.sum(np.array(w1))

exe.run(sync_program)
print '-------------'

w0 = fluid.global_scope().find_var("policy/fc_W").get_tensor()
w1 = fluid.global_scope().find_var("value/fc_W").get_tensor()
print np.sum(np.array(w0))
print np.sum(np.array(w1))
```

+ 输出信息：

```
-2.7668757
1.8978335
I0530 11:36:10.023646 294248 executor.cc:114] Create Variable feed global, which pointer is 0x5abd9e50
I0530 11:36:10.023655 294248 scope.cc:56] Create variable value/fc_W
I0530 11:36:10.023659 294248 executor.cc:119] Create Variable value/fc_W locally, which pointer is 0x5abdcbf0
I0530 11:36:10.023664 294248 executor.cc:114] Create Variable fetch global, which pointer is 0x5abd9df0
I0530 11:36:10.023669 294248 scope.cc:56] Create variable value/fc_b
I0530 11:36:10.023672 294248 executor.cc:119] Create Variable value/fc_b locally, which pointer is 0x5abd9cd0
I0530 11:36:10.023681 294248 executor.cc:334] CPUPlace Op(assign), inputs:{X[policy/fc_W[5, 10]({})]}, outputs:{Out[value/fc_W[0]({})]}.
I0530 11:36:10.023689 294248 tensor_util.cu:24] TensorCopy 5, 10 from CPUPlace to CPUPlace
I0530 11:36:10.023697 294248 tensor_util.cu:40] TensorCopy Done
I0530 11:36:10.023705 294248 executor.cc:334] CPUPlace Op(assign), inputs:{X[policy/fc_b[10]({})]}, outputs:{Out[value/fc_b[0]({})]}.
I0530 11:36:10.023710 294248 tensor_util.cu:24] TensorCopy 10 from CPUPlace to CPUPlace
I0530 11:36:10.023715 294248 tensor_util.cu:40] TensorCopy Done
I0530 11:36:10.023720 294248 scope.cc:40] Destroy variable value/fc_b
I0530 11:36:10.023726 294248 scope.cc:40] Destroy variable value/fc_W
-------------
-2.7668757 
1.8978335
```

+ 解决方法：

观察上述提供的代码，发现没有在sync_prgram中使用create_parameter()，该方法会创建一个参数，该参数是一个可学习的变量，即它是可以随着模型的训练而变化的，而且该方法是一个比较低级的API，通常在自定义运算符时使用，完整的使用为`paddle.fluid.layers.create_parameter()`

该方法更多内容，请参考PaddlePaddle API文档：http://www.paddlepaddle.org/documentation/api/zh/1.0.0/layers.html


+ 问题拓展：
代码中使用了rllab，这里简单介绍一下rllab，rllab是一个研究强化学习算法的框架。官方网站为https://github.com/openai/rllab。官方支持python 3.5+，基于Theano。与OpenAI Gym的区别在于OpenAI Gym支持更广泛的环境，且提供在线的scoreboard可以用于共享训练结果。rllab自己也提供一个基于pygame的可视环境，同时它也可兼容OpenAI Gym。除此之外，它提供了一些强化学习算法的实现，这些参考实现和一些组件可以使得强化学习算法的开发更快上手。安装步骤可按照官方网站：https://rllab.readthedocs.io/en/latest/user/installation.html。


## `已审核`7.问题：Fluid版本如何自定义模型权重？

+ 版本号：`1.1.0`

+ 标签：`自定义权重`

+ 问题描述：Fluid版本的PaddlePaddle如何自定义模型的权重？想要实现：x = MW + b，其中M是一个m * n的矩阵数据，W（n * 1）、b (m * 1)是自定义的权重。

+ 问题分析：

在Fluid版本中自定义权重可以通过`fluid.param_attr.ParamAttr()`方法的initializer参数实现，本地就是将自定义的值赋值给该节点，实现自定义模型权重的目的。

+ 解决方法：

自定义权重的实例代码如下：

```python
import paddle.fluid as fluid
import paddle
import numpy as np

def test_initializer(self):
    def initializer(name):
        assert name == 'fc.w'
        mat =  np.ones((3,2), dtype=np.float32)
        mat[1,1] = 2
        return mat

    x = fluid.layers.data(name='x', dtype='float32')
    y = fluid.layers.fc(input=x, size=2, param_attr=fluid.param_attr.ParamAttr(
        name='fc.w', initializer=initializer
    ))
```


## `已审核`8.问题：Fluid如何在输入层定义batch_size大小？

+ 版本号：`1.1.0`

+ 标签：`自定义batch_size`

+ 问题描述：我想尝试不同的batch_size大小，以观察不同batch_size大小对模型本身的影响

+ 相关代码：

```python
x = fluid.layers.data(name='x', shape=[13], dtype='float32')
y_predict = fluid.layers.fc(input=x, size=1, act=None)
y = fluid.layers.data(name='y', shape=[1], dtype='float32')
cost = fluid.layers.square_error_cost(input=y_predict, label=y)
```

+ 问题分析：

在Fluid版的Paddle中通常使用paddle.batch()方法来设置输入数据的大小，但并不一定要显示的定义在输入层，因为Fluid版的paddle会自动更加你输入数据的batch_size大小自动定义输入层batch_size的大小，保证输入数据与输入层batch_size始终是相同的。当然，如果想要显示调用也是完全可以的。例如：

```
固定batch size维度
image = fluid.layers.data(name="image", shape=[32, 784], append_batch_size=False)
```


+ 解决方法：

通常通过paddle.batch()定义输入batch_size大小的输入数据，Paddle的输入层，即fluid.layers.data()方法会自动将输入层的大小改成与paddle.batch()定义的batch_size相同的大小

```python
trainer.train(
        reader=paddle.batch(
            paddle.reader.shuffle(uci_housing.train(), buf_size=500),
            batch_size=2),
        feeding=feeding,
        event_handler=event_handler,
        num_passes=30)
```


## `已审核`9.问题：Fluid版本中如何使用序列数据？

+ 版本号：`1.1.0`

+ 标签：`序列数据`

+ 问题描述：在旧版的Paddle中可以使用三种序列格式来使用序列数据，但在Fluid版中这些功能都消失了，那我现在该如何在Fluid版的Paddle中使用序列数据呢？

+ 问题分析：
Fluid版是一个比较大的改进版本，从多方面考虑后，并没有很完美的向后兼容，这就造成旧版Paddle中的方法并不能再Fluid使用，在Fluid中所有的数据类型都为LoD-Tensor，对于不存在序列信息的数据（如此处的变量X），其lod_level=0，如果是存在序列的数据则根据需求设置不同的lod_level则可。


+ 问题解决：

可以直接使用`fluid.create_lod_tensor()`方法来使用序列数据，该方法的主要作用就是从numpy数组，表或现有的lod张量创建lod张量。实例如下：

```
import paddle.fluid as fluid

data1 = [[211]]  
data2 = [[6]]  
lod = [[1]]

place = fluid.CPUPlace()

first_word = fluid.create_lod_tensor(data1, lod, place)
second_word = fluid.create_lod_tensor(data2, lod, place)
```

更多细节可以参考LoDTensor文档：http://www.paddlepaddle.org/documentation/docs/zh/1.1/user_guides/howto/prepare_data/lod_tensor.html#

+ 问题拓展：
create_lod_tensor函数从一个numpy数组，列表或者已经存在的lod tensor中创建一个lod tensor。

通过一下几步实现:

1.检查length-based level of detail (LoD,长度为基准的细节层次)，或称recursive_sequence_lengths(递归序列长度)的正确性
2.将recursive_sequence_lengths转化为offset-based LoD(偏移量为基准的LoD)
3.把提供的numpy数组，列表或者已经存在的lod tensor复制到CPU或GPU中(依据执行场所确定)
4.利用offset-based LoD来设置LoD

## `已审核`10.在Paddle中如何创建并使用自己创建的reader数据读入者

+ 版本号：`1.1.0`

+ 标签：  `创建reader`

+ 问题描述：想在Fluid中使用自己的数据集，但不知如何创建一个reader来使用自己的数据

+ 问题分析：Paddle为了让使用者更加容易上手，对很多实例数据进行了封装，方便直接使用，这些实例数据的封装代码，具体封装好的数据有：

```
import paddle.dataset.mnist
import paddle.dataset.imikolov
import paddle.dataset.imdb
import paddle.dataset.cifar
import paddle.dataset.movielens
import paddle.dataset.conll05
import paddle.dataset.uci_housing
import paddle.dataset.sentiment
import paddle.dataset.wmt14
import paddle.dataset.wmt16
import paddle.dataset.mq2007
import paddle.dataset.flowers
import paddle.dataset.voc2012
import paddle.dataset.image
```

封装的逻辑其实具有普适性，你可以模仿封装代码中定义reader数据读入者的方法。


+ 解决方法：

这里写一个简单的reader，代码如下：

```python
import paddle.fluid as fluid
import paddle

def reader_createor(data, label):
    def reader():
        for i in  range(len(data)):
            yield data[i,:], int(label[i])
    return reader


train_reader = paddle.batch(
    paddle.reader.shuffle(
        reader=reader_createor(data, label),buf_size=200
    ), batch_size=16
)
```

其中reader_createor用于创建数据，使用了python的yield字段，即将方法变成了生成器，这里可以同时生成数据与对应的标签，然后使用paddle.batch()方法来调用reader_createor，实现自己数据的读入。然后就可以将该读入器train_reader用于训练中了。


## `已审核`11.Fluid如何实现异步加载数据？

+ 版本号：`1.1.0`

+ 标签：`数据异步加载`

+ 问题描述：Fluid是否支持异步加载数据？如果支持，如何实现？

+ 问题分析：Fluid是支持异步加载数据的，使用`fluid.layers.py_reader()`方法即可实现数据的异步加载

+ 解决方法：

```
import paddle.fluid as fluid

train_py_reader = fluid.layers.py_reader(capacity=64,
                                         shapes=[(-1,3,224,224), (-1,1)],
                                         dtypes=['float32', 'int64'],
                                         name='train',
                                         use_double_buffer=True)

test_py_reader = fluid.layers.py_reader(capacity=64,
                                        shapes=[(-1,3,224,224), (-1,1)],
                                        dtypes=['float32', 'int64'],
                                        name='test',
                                        use_double_buffer=True)
```

异步加载数据的速度相比同步加载数据要快不少，且异步加载数据在文档中有单独提及，具体在http://paddlepaddle.org/documentation/docs/zh/1.2/user_guides/howto/prepare_data/use_py_reader.html


## `已审核`13.问题：Paddle如何加快读取数据的速度？

+ 版本号：`1.1.0`

+ 标签：`加快数据读取速度`

+ 问题描述：在使用Fluid版的Paddle编写模型时，需要对数据进行增量处理，训练数据为图像数据，我对它们做了常规的变形操作，并使用多线程来加速，但感觉数据读取部分依旧很慢，如何解决？

+ 相关代码：

```python
from PIL import Image
import numpy as np
import random

def train_mapper(sample):
    img, label = sample
    img = Image.open(img)
    r1 = random.random()
    if r1 > 0.5:
        img = img.transpose(Image.FLIP_LEFT_RIGHT)
    r2 = random.random()
    if r2 > 0.5:
        img = img.transpose(Image.FLIP_TOP_BOTTOM)

    img = np.array(img).astype(np.float32)
    #转成CHW
    img = img.transpose((2,0,1))
    img = img[(2,1,0),:,:] /255.
    return img, int(label)
```


+ 解决方法：

Paddle读入数据时使用PyReader对象而不是常见的`executor.run(feed=...)`方法来读取数据，PyReader对象读取数据使用的是异步方式，读取的速度回快上许多。示例代码如下：

```python
import paddle.fluid as fluid

train_py_reader = fluid.layers.py_reader(capacity=64,
                                         shapes=[(-1,3,224,224), (-1,1)],
                                         dtypes=['float32', 'int64'],
                                         name='train',
                                         use_double_buffer=True)

test_py_reader = fluid.layers.py_reader(capacity=64,
                                        shapes=[(-1,3,224,224), (-1,1)],
                                        dtypes=['float32', 'int64'],
                                        name='test',
                                        use_double_buffer=True)
```














