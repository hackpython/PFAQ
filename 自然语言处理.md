# 自然语言处理

## `待审核`1.问题：使用Fluid models中lstm相关的代码报错？

+ 问题描述：使用Fluid models中lstm相关的代码报错？

+ 报错输出：

```
Traceback (most recent call last):
  File "train.py", line 312, in <module>
    train()
  File "train.py", line 187, in train
    exe.run(framework.default_startup_program())
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/executor.py", line 470, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: Cannot run operator on place CUDAPlace(0) at [/Users/paddle/minqiyang/Paddle/paddle/fluid/framework/operator.cc:146]
PaddlePaddle Call Stacks:
0          0x116a7ca68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x1178a11f9p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 761
2          0x116b4a3a6p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 390
3          0x116b49dd3p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 163
4          0x116ab0837p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init()::$_64, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init()::$_64&&, void (*)(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 135
5          0x116a873aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
6          0x109d2e59fp PyCFunction_Call + 127
7          0x109df97e7p PyEval_EvalFrameEx + 33207
8          0x109deffafp _PyEval_EvalCodeWithName + 335
9          0x109df62a7p PyEval_EvalFrameEx + 19575
10         0x109deffafp _PyEval_EvalCodeWithName + 335
11         0x109df62a7p PyEval_EvalFrameEx + 19575
12         0x109deffafp _PyEval_EvalCodeWithName + 335
13         0x109e42758p PyRun_FileExFlags + 248
14         0x109e41eeep PyRun_SimpleFileExFlags + 382
15         0x109e66d86p Py_Main + 3622
16         0x109ca8861p main + 497
17      0x7fff75c56015p start + 1
```

+ 问题分析：

报错输出中出现：`Cannot run operator on place CUDAPlace`，该错误表示训练设备上没有GPU设备，使用CPU进行训练则可。

+ 解决方法：

使用CPU进行训练

```
place = fluid.CPUPlace()
```

## `待审核`2. 问题：Tensor holds the wrong type

+ 问题描述：使用Fluid编写LSTM时，出现Tensor holds the wrong type

+ 报错输出：

```
begin to load data
vocab word num 10000
finished load data
epoch id 0
Traceback (most recent call last):
  File "train.py", line 313, in <module>
    train()
  File "train.py", line 273, in train
    use_program_cache=True)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/executor.py", line 470, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: Tensor holds the wrong type, it holds d at [/Users/paddle/minqiyang/Paddle/paddle/fluid/framework/tensor_impl.h:29]
PaddlePaddle Call Stacks:
0          0x1180e2a68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x1180f8032p float const* paddle::framework::Tensor::data<float>() const + 258
2          0x118c9fca9p paddle::operators::SGDOpKernel<float>::Compute(paddle::framework::ExecutionContext const&) const + 2409
3          0x118c9f300p std::__1::__function::__func<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::SGDOpKernel<float>, paddle::operators::SGDOpKernel<double> >::operator()(char const*, char const*) const::'lambda'(paddle::framework::ExecutionContext const&), std::__1::allocator<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::SGDOpKernel<float>, paddle::operators::SGDOpKernel<double> >::operator()(char const*, char const*) const::'lambda'(paddle::framework::ExecutionContext const&)>, void (paddle::framework::ExecutionContext const&)>::operator()(paddle::framework::ExecutionContext const&) + 32
4          0x118f0b223p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 659
5          0x118f07141p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 577
6          0x1181b03a6p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 390
7          0x1181afdd3p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 163
8          0x118116837p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init()::$_64, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init()::$_64&&, void (*)(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 135
9          0x1180ed3aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
10         0x10b39659fp PyCFunction_Call + 127
11         0x10b4617e7p PyEval_EvalFrameEx + 33207
12         0x10b457fafp _PyEval_EvalCodeWithName + 335
13         0x10b45e2a7p PyEval_EvalFrameEx + 19575
14         0x10b457fafp _PyEval_EvalCodeWithName + 335
15         0x10b45e2a7p PyEval_EvalFrameEx + 19575
16         0x10b457fafp _PyEval_EvalCodeWithName + 335
17         0x10b4aa758p PyRun_FileExFlags + 248
18         0x10b4a9eeep PyRun_SimpleFileExFlags + 382
19         0x10b4ced86p Py_Main + 3622
20         0x10b310861p main + 497
21      0x7fff75c56015p start + 1
22                 0x8p
```

+ 相关代码：

```python
def prepare_input(batch, init_hidden, init_cell, epoch_id=0, with_lr=True):
    x, y = batch
    new_lr = base_learning_rate * (lr_decay**max(
        epoch_id + 1 - epoch_start_decay, 0.0))
    lr = np.ones((1)) * new_lr
    res = {}
    x = x.reshape((-1, num_steps, 1))
    y = y.reshape((-1, 1))
    res['x'] = x
    res['y'] = y
    res['init_hidden'] = init_hidden
    res['init_cell'] = init_cell
    if with_lr:
        res['learning_rate'] = lr

    return res

for batch_id, batch in enumerate(train_data_iter):
    input_data_feed = prepare_input(
        batch, init_hidden, init_cell, epoch_id=epoch_id)
    fetch_outs = exe.run(feed=input_data_feed,
                         fetch_list=[
                             loss.name, last_hidden.name,
                             last_cell.name, 'learning_rate'
                         ],
                         use_program_cache=True)
```

+ 问题分析：

Tensor holds the wrong type表示训练时使用的Tensor类型错误，该错误常发生在输入方法上，要注意feed获得的数据的类型是否正常，建议训练前先打印传入数据的变量与性状

+ 解决方法：

np.ones()默认的dtype为float64

```python
def prepare_input(batch, init_hidden, init_cell, epoch_id=0, with_lr=True):
    x, y = batch
    new_lr = base_learning_rate * (lr_decay**max(
        epoch_id + 1 - epoch_start_decay, 0.0))
    lr = np.ones((1), dtype='float32') * new_lr
    res = {}
    x = x.reshape((-1, num_steps, 1))
    y = y.reshape((-1, 1))

    res['x'] = x
    res['y'] = y
    res['init_hidden'] = init_hidden
    res['init_cell'] = init_cell
    if with_lr:
        res['learning_rate'] = lr

    return res
```

## `待审核`3.问题：Tensor not initialized yet when Tensor::type() is called.

+ 问题描述：Tensor not initialized yet when Tensor::type() is called.

+ 报错输出：

```
begin to load data
vocab word num 10000
finished load data
epoch id 0
Traceback (most recent call last):
  File "train.py", line 311, in <module>
    train()
  File "train.py", line 271, in train
    use_program_cache=True)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/executor.py", line 470, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: holder_ should not be null
Tensor not initialized yet when Tensor::type() is called. at [/Users/paddle/minqiyang/Paddle/paddle/fluid/framework/tensor.h:141]
PaddlePaddle Call Stacks:
0          0x117dd9a68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x117dd6c12p paddle::framework::Tensor::type() const + 194
2          0x1185af7f1p paddle::operators::ReshapeOp::GetExpectedKernelType(paddle::framework::ExecutionContext const&) const + 81
3          0x118c02099p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 265
4          0x118bfe141p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 577
5          0x117ea73a6p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 390
6          0x117ea6dd3p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 163
7          0x117e0d837p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init()::$_64, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init()::$_64&&, void (*)(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 135
8          0x117de43aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
9          0x10b07359fp PyCFunction_Call + 127
10         0x10b13e7e7p PyEval_EvalFrameEx + 33207
11         0x10b134fafp _PyEval_EvalCodeWithName + 335
12         0x10b13b2a7p PyEval_EvalFrameEx + 19575
13         0x10b134fafp _PyEval_EvalCodeWithName + 335
14         0x10b13b2a7p PyEval_EvalFrameEx + 19575
15         0x10b134fafp _PyEval_EvalCodeWithName + 335
16         0x10b187758p PyRun_FileExFlags + 248
17         0x10b186eeep PyRun_SimpleFileExFlags + 382
18         0x10b1abd86p Py_Main + 3622
19         0x10afed861p main + 497
20      0x7fff75c56015p start + 1
21                 0x8p
```

+ 报错代码：

```python
init_hidden = np.zeros((num_layers, batch_size, hidden_size), dtype='float32')
init_cell = np.zeros((num_layers, batch_size, hidden_size), dtype='float32')
for batch_id, batch in enumerate(eval_data_iter):
    input_data_feed = prepare_input(
        batch, init_hidden, init_cell, epoch_id, with_lr=False)
    fetch_outs = exe.run(
        inference_program,
        fetch_list=[loss.name, last_hidden.name, last_cell.name],
        use_program_cache=True)

    cost_train = np.array(fetch_outs[0])
    init_hidden = np.array(fetch_outs[1])
    init_cell = np.array(fetch_outs[2])
```

+ 问题分析：

Tensor not initialized yet when Tensor::type() is called.报错通常表明训练数据在被调用时，没有被初始化。导致该错误的原因通常是没有传入数据或读入数据的方法有问题

+ 解决方法：

报错代码中，忘记了将数据传递给feed参数，传递相应的训练数据给feed参数则可。

```python
init_hidden = np.zeros((num_layers, batch_size, hidden_size), dtype='float32')
init_cell = np.zeros((num_layers, batch_size, hidden_size), dtype='float32')
for batch_id, batch in enumerate(eval_data_iter):
    input_data_feed = prepare_input(
        batch, init_hidden, init_cell, epoch_id, with_lr=False)
    fetch_outs = exe.run(
        inference_program,
        feed=input_data_feed,
        fetch_list=[loss.name, last_hidden.name, last_cell.name],
        use_program_cache=True)

    cost_train = np.array(fetch_outs[0])
    init_hidden = np.array(fetch_outs[1])
    init_cell = np.array(fetch_outs[2])
```


## `待审核`4.问题：Enforce failed

+ 问题描述：Fluid编写LSTM无法运行，报Enforce failed

+ 报错输出：

```
Traceback (most recent call last):
  File "train.py", line 311, in <module>
    train()
  File "train.py", line 271, in train
    use_program_cache=True)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/executor.py", line 470, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: Enforce failed. Expected table_dims.size() == 2, but received table_dims.size():1 != 2:2.
 at [/Users/paddle/minqiyang/Paddle/paddle/fluid/operators/lookup_table_op.cc:37]
PaddlePaddle Call Stacks:
0          0x11cecba68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x11d6c965cp paddle::operators::LookupTableOp::InferShape(paddle::framework::InferShapeContext*) const + 2012
2          0x11dcf3fe8p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 88
3          0x11dcf0141p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 577
4          0x11cf993a6p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 390
5          0x11cf98dd3p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 163
6          0x11ceff837p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init()::$_64, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init()::$_64&&, void (*)(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 135
7          0x11ced63aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
8          0x10f23d59fp PyCFunction_Call + 127
9          0x10f3087e7p PyEval_EvalFrameEx + 33207
10         0x10f2fefafp _PyEval_EvalCodeWithName + 335
11         0x10f3052a7p PyEval_EvalFrameEx + 19575
12         0x10f2fefafp _PyEval_EvalCodeWithName + 335
13         0x10f3052a7p PyEval_EvalFrameEx + 19575
14         0x10f2fefafp _PyEval_EvalCodeWithName + 335
15         0x10f351758p PyRun_FileExFlags + 248
16         0x10f350eeep PyRun_SimpleFileExFlags + 382
17         0x10f375d86p Py_Main + 3622
18         0x10f1b7861p main + 497
19      0x7fff75c56015p start + 1
20                 0x8p
```

+ 相关代码：

```python
optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)

optimizer.minimize(loss)

place = core.CUDAPlace(0) if args.use_gpu else core.CPUPlace()
exe = Executor(place)

data_path = args.data_path
print("begin to load data")
raw_data = reader.ptb_raw_data(data_path)
print("finished load data")
train_data, valid_data, test_data, _ = raw_data
```

+ 问题分析：

从报错日志的错误栈看出Enforce failed错误，强制执行失败，造成该错误的情况有多种，从错误栈的其他详细信息来看，program在开始初始化时就出现错误，所以需要关注一下程序初始化那块的代码

+ 解决方法：

```python
optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)

optimizer.minimize(loss)

place = core.CUDAPlace(0) if args.use_gpu else core.CPUPlace()
exe = Executor(place)
exe.run(framework.default_startup_program()) 
data_path = args.data_path
print("begin to load data")
raw_data = reader.ptb_raw_data(data_path)
print("finished load data")
train_data, valid_data, test_data, _ = raw_data
```

## `待审核`5.问题：Fluid实现的网络训练时梯度波动太大

+ 问题描述：Fluid实现的网络训练时梯度波动太大

+ 相关代码：

```python
main_program = fluid.default_main_program()
inference_program = fluid.default_main_program().clone(for_test=True)

fluid.clip.set_gradient_clip(clip=fluid.clip.GradientClipByGlobalNorm(
    clip_norm=max_grad_norm))

learning_rate = fluid.layers.create_global_var(
    name="learning_rate",
    shape=[1],
    value=1.0,
    dtype='int32',
    persistable=True)

optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)

optimizer.minimize(loss)
```

+ 问题分析：

训练时梯度波动太大通常是没有正确设置优化算法的学习速率导致的，注意学习速率的类型

+ 解决方法：

将学习速率的类型改为flaot32，int32类型会导致学习速率无法细致的变化

```python
main_program = fluid.default_main_program()
inference_program = fluid.default_main_program().clone(for_test=True)

fluid.clip.set_gradient_clip(clip=fluid.clip.GradientClipByGlobalNorm(
    clip_norm=max_grad_norm))

learning_rate = fluid.layers.create_global_var(
    name="learning_rate",
    shape=[1],
    value=1.0,
    dtype='float32',
    persistable=True)

optimizer = fluid.optimizer.SGD(learning_rate=learning_rate)

optimizer.minimize(loss)
```


## `待审核`6.问题：Data Type mismatch: 5 to 2

+ 问题描述：Fluid报Data Type mismatch: 5 to 2错误

+ 报错输出：

```python
Traceback (most recent call last):
  File "train.py", line 309, in <module>
    train()
  File "train.py", line 182, in train
    optimizer.minimize(loss)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/optimizer.py", line 263, in minimize
    params_grads = append_gradient_clip_ops(params_grads)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/clip.py", line 353, in append_gradient_clip_ops
    res.append(clip_attr._create_operators(param=p, grad=g))
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/clip.py", line 283, in _create_operators
    group_norm_var = layers.sums(input=self.context[self.group_name])
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layers/tensor.py", line 225, in sums
    dtype=helper.input_dtype())
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layer_helper.py", line 109, in input_dtype
    (dtype, each.dtype))
ValueError: Data Type mismatch: 5 to 2
```

+ 报错代码：

```python
for i in range(num_layers):
    weight_1 = layers.create_parameter([hidden_size * 2, hidden_size*4], dtype="int32", name="fc_weight1_"+str(i), \
            default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
    weight_1_arr.append(weight_1)
    bias_1 = layers.create_parameter(
        [hidden_size * 4],
        dtype="float32",
        name="fc_bias1_" + str(i),
        default_initializer=fluid.initializer.Constant(0.0))
    bias_arr.append(bias_1)
```

+ 问题分析：

Data Type mismatch类错误通常是由传入的数据与接受数据节点的类型不匹配导致的

+ 问题解决：

```python
for i in range(num_layers):
    weight_1 = layers.create_parameter([hidden_size * 2, hidden_size*4], dtype="float32", name="fc_weight1_"+str(i), \
            default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
    weight_1_arr.append(weight_1)
    bias_1 = layers.create_parameter(
        [hidden_size * 4],
        dtype="float32",
        name="fc_bias1_" + str(i),
        default_initializer=fluid.initializer.Constant(0.0))
    bias_arr.append(bias_1)
```



## `待审核`7.问题： Enforce failed. Expected x_dims[i + axis] == y_dims[i], but received x_dims[i + axis]:800 != y_dims[i]:200.

+ 问题描述：程序训练时，报出错误

+ 报粗输出：

```
Traceback (most recent call last):
  File "train.py", line 309, in <module>
    train()
  File "train.py", line 269, in train
    use_program_cache=True)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/executor.py", line 470, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: Enforce failed. Expected x_dims[i + axis] == y_dims[i], but received x_dims[i + axis]:800 != y_dims[i]:200.
Broadcast dimension mismatch. at [/Users/paddle/minqiyang/Paddle/paddle/fluid/operators/elementwise_op_function.h:63]
PaddlePaddle Call Stacks:
0          0x1172fda68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x11780445cp paddle::operators::get_mid_dims(paddle::framework::DDim const&, paddle::framework::DDim const&, int, int*, int*, int*) + 540
2          0x1178f1b9ep void paddle::operators::ElementwiseComputeEx<paddle::operators::AddFunctor<float>, paddle::platform::CPUDeviceContext, float, float>(paddle::framework::ExecutionContext const&, paddle::framework::Tensor const*, paddle::framework::Tensor const*, int, paddle::operators::AddFunctor<float>, paddle::framework::Tensor*) + 1598
3          0x11799ac69p paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const + 937
4          0x11799a880p std::__1::__function::__func<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, long long> >::operator()(char const*, char const*) const::'lambda'(paddle::framework::ExecutionContext const&), std::__1::allocator<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, double>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, int>, paddle::operators::ElementwiseAddKernel<paddle::platform::CPUDeviceContext, long long> >::operator()(char const*, char const*) const::'lambda'(paddle::framework::ExecutionContext const&)>, void (paddle::framework::ExecutionContext const&)>::operator()(paddle::framework::ExecutionContext const&) + 32
5          0x118126223p paddle::framework::OperatorWithKernel::RunImpl(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) const + 659
6          0x118122141p paddle::framework::OperatorBase::Run(paddle::framework::Scope const&, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&) + 577
7          0x1173cb3a6p paddle::framework::Executor::RunPreparedContext(paddle::framework::ExecutorPrepareContext*, paddle::framework::Scope*, bool, bool, bool) + 390
8          0x1173cadd3p paddle::framework::Executor::Run(paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool) + 163
9          0x117331837p void pybind11::cpp_function::initialize<paddle::pybind::pybind11_init()::$_64, void, paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::pybind11_init()::$_64&&, void (*)(paddle::framework::Executor&, paddle::framework::ProgramDesc const&, paddle::framework::Scope*, int, bool, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&) + 135
10         0x1173083aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
11         0x10a5cf59fp PyCFunction_Call + 127
12         0x10a69a7e7p PyEval_EvalFrameEx + 33207
13         0x10a690fafp _PyEval_EvalCodeWithName + 335
14         0x10a6972a7p PyEval_EvalFrameEx + 19575
15         0x10a690fafp _PyEval_EvalCodeWithName + 335
16         0x10a6972a7p PyEval_EvalFrameEx + 19575
17         0x10a690fafp _PyEval_EvalCodeWithName + 335
18         0x10a6e3758p PyRun_FileExFlags + 248
19         0x10a6e2eeep PyRun_SimpleFileExFlags + 382
20         0x10a707d86p Py_Main + 3622
21         0x10a549861p main + 497
22      0x7fff75c56015p start + 1
23                 0x8p
```

+ 相关代码：

```python
weight_1 = layers.create_parameter([hidden_size * 2, hidden_size*4], dtype="float32", name="fc_weight1_"+str(i), \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
weight_1_arr.append(weight_1)
bias_1 = layers.create_parameter(
    [hidden_size],
    dtype="float32",
    name="fc_bias1_" + str(i),
    default_initializer=fluid.initializer.Constant(0.0))
bias_arr.append(bias_1)
```

+ 问题分析：

错误`Expected x_dims[i + axis] == y_dims[i], but received x_dims[i + axis]:800 != y_dims[i]` 表明网络结构存在不匹配的问题，需要检查一下自己的网络结构与相关的编写逻辑，将结构与对应的操作逻辑对应上。

+ 解决方法：

```python
weight_1 = layers.create_parameter([hidden_size * 2, hidden_size*4], dtype="float32", name="fc_weight1_"+str(i), \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
weight_1_arr.append(weight_1)
bias_1 = layers.create_parameter(
    [hidden_size*4],
    dtype="float32",
    name="fc_bias1_" + str(i),
    default_initializer=fluid.initializer.Constant(0.0))
bias_arr.append(bias_1)
```


## `待审核`8.问题：Fluid运行编写好的LSTM报错

+ 问题描述：Fluid运行编写好的LSTM报错，报错内容为`Enforce failed. Expected capacity == in_size, but received capacity:200 != in_size:-200.`

+ 报错输出：

```
Traceback (most recent call last):
  File "train.py", line 309, in <module>
    train()
  File "train.py", line 165, in train
    rnn_model=rnn_model)
  File "/Users/ayuliao/Desktop/Paddle/models/fluid/PaddleNLP/language_model/lstm/lm_model.py", line 270, in lm_model
    x_emb, len=num_steps, init_hidden=init_hidden, init_cell=init_cell)
  File "/Users/ayuliao/Desktop/Paddle/models/fluid/PaddleNLP/language_model/lstm/lm_model.py", line 224, in encoder_static
    res.append(layers.reshape(input, shape=[1, 1, hidden_size]))
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layers/nn.py", line 4979, in reshape
    "XShape": x_shape})
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layer_helper.py", line 50, in append_op
    return self.main_program.current_block().append_op(*args, **kwargs)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/framework.py", line 1207, in append_op
    op = Operator(block=self, desc=op_desc, *args, **kwargs)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/framework.py", line 656, in __init__
    self.desc.infer_shape(self.block.desc)
paddle.fluid.core.EnforceNotMet: Enforce failed. Expected capacity == in_size, but received capacity:200 != in_size:-200.
Invalid shape is given. at [/Users/paddle/minqiyang/Paddle/paddle/fluid/operators/reshape_op.cc:103]
PaddlePaddle Call Stacks:
0          0x111feda68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x1127c3e07p paddle::operators::ReshapeOp::ValidateShape(std::__1::vector<int, std::__1::allocator<int> >, paddle::framework::DDim const&) + 1463
2          0x1127c3165p paddle::operators::ReshapeOp::InferShape(paddle::framework::InferShapeContext*) const + 773
3          0x1127c9cefp paddle::operators::Reshape2Op::InferShape(paddle::framework::InferShapeContext*) const + 703
4          0x1120aae68p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 1496
5          0x112074479p _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework6OpDescEJRKNS4_9BlockDescEEJNS_4nameENS_9is_methodENS_7siblingEEEEMT0_KFT_DpT1_EDpRKT2_EUlPKS5_S8_E_vJSN_S8_EJS9_SA_SB_EEEvOSD_PFSC_SF_ESL_ENKUlRNS_6detail13function_callEE_clESU_ + 185
6          0x111ff83aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
7          0x1052a859fp PyCFunction_Call + 127
8          0x1053737e7p PyEval_EvalFrameEx + 33207
9          0x105369fafp _PyEval_EvalCodeWithName + 335
10         0x1052756aap function_call + 106
11         0x105231b35p PyObject_Call + 69
12         0x105254694p method_call + 148
13         0x105231b35p PyObject_Call + 69
14         0x1052ce415p slot_tp_init + 117
15         0x1052d2ac1p type_call + 209
16         0x105231b35p PyObject_Call + 69
17         0x105370c9bp PyEval_EvalFrameEx + 22123
18         0x105369fafp _PyEval_EvalCodeWithName + 335
19         0x1052756aap function_call + 106
20         0x105231b35p PyObject_Call + 69
21         0x105370c9bp PyEval_EvalFrameEx + 22123
22         0x105369fafp _PyEval_EvalCodeWithName + 335
23         0x1053702a7p PyEval_EvalFrameEx + 19575
24         0x105369fafp _PyEval_EvalCodeWithName + 335
25         0x1053702a7p PyEval_EvalFrameEx + 19575
26         0x105369fafp _PyEval_EvalCodeWithName + 335
27         0x1053702a7p PyEval_EvalFrameEx + 19575
28         0x105369fafp _PyEval_EvalCodeWithName + 335
29         0x1053702a7p PyEval_EvalFrameEx + 19575
30         0x105369fafp _PyEval_EvalCodeWithName + 335
31         0x1053702a7p PyEval_EvalFrameEx + 19575
32         0x105369fafp _PyEval_EvalCodeWithName + 335
33         0x1053bc758p PyRun_FileExFlags + 248
34         0x1053bbeeep PyRun_SimpleFileExFlags + 382
35         0x1053e0d86p Py_Main + 3622
36         0x105222861p main + 497
37      0x7fff75c56015p start + 1
38                 0x8p
```

+ 相关代码：

```
input = layers.reshape(input, shape=[-1, hidden_size])
for k in range(num_layers):
    pre_hidden = hidden_array[k]
    pre_cell = cell_array[k]
    weight_1 = weight_1_arr[k]
    bias = bias_arr[k]

    nn = layers.concat([input, pre_hidden], 1)
    gate_input = layers.matmul(x=nn, y=weight_1)

    gate_input = layers.elementwise_add(gate_input, bias)
    i, j, f, o = layers.split(gate_input, num_or_sections=4, dim=-1)

    c = pre_cell * layers.sigmoid(f) + layers.sigmoid(
        i) * layers.tanh(j)
    m = layers.tanh(c) * layers.sigmoid(o)

    hidden_array[k] = m
    cell_array[k] = c
    input = m

    if dropout != None and dropout > 0.0:
        input = layers.dropout(
            input,
            dropout_prob=dropout,
            dropout_implementation='upscale_in_train')

res.append(layers.reshape(input, shape=[1, 1, hidden_size]))
```

+ 问题分析：

参考问题7，`Enforce failed. Expected capacity == in_size, but received capacity:200 != in_size:-200.`报错表示强制执行失败，失败的缘由是`Expected capacity == in_size, but received capacity:200 != in_size:-200.`，通常是网络结构与操作逻辑不匹配导致

+ 解决方法：

将append进res的元素其shape的第二维改为-1

```
input = layers.reshape(input, shape=[-1, hidden_size])
for k in range(num_layers):
    pre_hidden = hidden_array[k]
    pre_cell = cell_array[k]
    weight_1 = weight_1_arr[k]
    bias = bias_arr[k]

    nn = layers.concat([input, pre_hidden], 1)
    gate_input = layers.matmul(x=nn, y=weight_1)

    gate_input = layers.elementwise_add(gate_input, bias)
    i, j, f, o = layers.split(gate_input, num_or_sections=4, dim=-1)

    c = pre_cell * layers.sigmoid(f) + layers.sigmoid(
        i) * layers.tanh(j)
    m = layers.tanh(c) * layers.sigmoid(o)

    hidden_array[k] = m
    cell_array[k] = c
    input = m

    if dropout != None and dropout > 0.0:
        input = layers.dropout(
            input,
            dropout_prob=dropout,
            dropout_implementation='upscale_in_train')

res.append(layers.reshape(input, shape=[1, -1, hidden_size]))
```
















