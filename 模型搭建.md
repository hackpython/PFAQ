# 模型搭建

## `待审核` 1.问题：如何移植v2模型到fluid?

+ 问题描述：deep fm从paddlepaddle v2 版模型`https://github.com/PaddlePaddle/models/tree/develop/legacy/deep_fm`移植到fluid。但是我找不到移植指导文档。特别是v2中的数据类型如何对应到fluid中：`paddle.data_type.dense_vector`，`paddle.data_type.sparse_binary_vector`，`paddle.data_type.integer_value`

+ 问题解答：
	1.layers.data只需要指定lod_level即可，dense_vector, interge_value默认都可以不用制定lod_level
	2.reader的返回还可以复用v2的reader， dense_vector返回numpy.array

	具体的代码细节可以参考：https://github.com/PaddlePaddle/models/tree/develop/fluid/PaddleRec/ctr


## `待审核`2.问题：如何使用Fluid的流程控制？

+ 问题描述：参考了官方文档中主要的几个例子，似乎都是常见的模式，如何使用Fluid的流程机制？

+ 问题解答：

流程控制方面的内容都放在了`fluid.layers.control_flow`模块下，里面包含了While、Block、Conditional、Switch、if、ifelse等跟中操作，这样可以让在编写模型时，像编写普通的python程序一样。

```
lr = fluid.layers.tensor.create_global_var(
    shape=[1],
    value=0.0,
    dtype='float32',
    persistable=True,
    name='learning_rate'
)
one_var = fluid.layers.fill_constant(
    shape=[1], dtype='float32', value=1.0
)
two_var = fluid.layers.fill_constant(
    shape=[1], dtype='float32', value=2.0
)

# switch
with fluid.layers.control_flow.Switch() as switch:
    with switch.case(global_step == one_var):
        fluid.layers.tensor.assign(input=one_var, output=lr)
        with switch.default():
            fluid.layers.tensor.assign(input=two_var, output=lr)
```


+ 问题拓展：

动态计算意味着程序将按照我们编写命令的顺序进行执行。这种机制将使得调试更加容易，并且也使得我们将大脑中的想法转化为实际代码变得更加容易。而静态计算则意味着程序在编译执行时将先生成神经网络的结构，然后再执行相应操作。从理论上讲，静态计算这样的机制允许编译器进行更大程度的优化，但是这也意味着你所期望的程序与编译器实际执行之间存在着更多的代沟。这也意味着，代码中的错误将更加难以发现（比如，如果计算图的结构出现问题，你可能只有在代码执行到相应操作的时候才能发现它）。


## `待审核`3.问题：Fluid如何实现分布式网络架构？

+ 问题描述：目前有多个物理主机，现在想通过Fluid来构建一个分布式的训练网络，如何实现？

+ 问题分析：可以使用`paddle.fluid.Distribut`类，该类可以把fluid program转变为分布式数据并行计算程序（distributed data-parallelism programs）,可以有Pserver和NCCL2两种模式。


+ 解决方法：

`paddle.fluid.Distribut`类pserver模式的实例代码如下：

```
#pserver模式下
pserver_endpoints = "192.168.0.1:6174,192.168.0.2:6174"
trainer_endpoints = "192.168.0.1:6174,192.168.0.2:6174"
current_endpoint = "192.168.0.1:6174"
trainer_id = 0
trainers = 4
role = os.getenv("PADDLE_TRAINING_ROLE")

t = fluid.DistributeTranspiler()
t.transpile(
     trainer_id, pservers=pserver_endpoints, trainers=trainers)
if role == "PSERVER":
     pserver_program = t.get_pserver_program(current_endpoint)
     pserver_startup_program = t.get_startup_program(current_endpoint,
                                             pserver_program)
elif role == "TRAINER":
     trainer_program = t.get_trainer_program()
```

关于该类更多的内容，可以参考：http://www.paddlepaddle.org/documentation/api/en/0.15.0/transpiler.html#distributetranspiler

+ 问题拓展：

分布式训练深度学习模型在技术实现上是存在挑战的，其抽象整体结构如下图：

![](https://raw.githubusercontent.com/ayuLiao/images/master/distributedeeplearning.png)

其实设计了很多技术细节，可以参考下面文章：

http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/

## `待审核`4.问题：如何获得模型的参数？

+ 问题描述：在训练模型时，如何获得模型的参数？

+ 问题分析：在Fluid中要获得模型对应的参数，需要理解Fluid中Program方面的设计，主要就是要理解Programs and Blocks，在Fluid 的 Program 的基本结构是一些嵌套 blocks，形式上类似一段 C++ 或 Java 程序。

blocks中包含：
1.本地变量的定义
2.一系列的operator

那么通过Program的blocks就可以获得对应网络的参数节点对象


+ 解决方法：

一段示例代码如下：

```
program = fluid.Program()

p.name for p in program.global_block().all_parameters()
```

这里通过fluid.Program()定义program实例，然后通过global_block().all_parameters()获得该program所有节点的对象。

更多相关内容可以参考Fluid设计方面的文档：http://paddlepaddle.org/documentation/docs/zh/1.1/user_guides/design_idea/fluid_design_idea.html














