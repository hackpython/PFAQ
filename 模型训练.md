# 模型训练

## `待审核`1.问题：Fluid接口是否可以同时训练2个不同的网络

+ 问题描述：我是否可以使用Fluid版本的PaddlePaddle实现同时训练2个不同的网络

+ 问题解答：
这是可以的，同时训练2个不同的网络是比较常见的需求，Fluid可以请求实现这个需求，简单而言你只需要定义两个网络结构，然后调用执行器分别执行这两个网络这可。

+ 解决方法：

这里定义简单的GAN来实现同时训练2个不同的网络，部分代码如下：

```
def D(x):
    hidden = fluid.layers.fc(input=x,
                             size=200,
                             act='relu',
                             param_attr='D.w1',
                             bias_attr='D.b1')
    logits = fluid.layers.fc(input=hidden,
                             size=1,
                             act=None,
                             param_attr='D.w2',
                             bias_attr='D.b2')
    return logits


def G(x):
    hidden = fluid.layers.fc(input=x,
                             size=200,
                             act='relu',
                             param_attr='G.w1',
                             bias_attr='G.b1')
    img = fluid.layers.fc(input=hidden,
                          size=28 * 28,
                          act='tanh',
                          param_attr='G.w2',
                          bias_attr='G.b2')
    return img


def main():
	 ...

	 with fluid.program_guard(dg_program, startup_program):
	    noise = fluid.layers.data(
	        name='noise', shape=[NOISE_SIZE], dtype='float32')
	    g_img = G(x=noise)
	    g_program = dg_program.clone()
	    dg_loss = fluid.layers.sigmoid_cross_entropy_with_logits(
	        x=D(g_img),
	        label=fluid.layers.fill_constant_batch_size_like(
	            input=noise, dtype='float32', shape=[-1, 1], value=1.0))
	    dg_loss = fluid.layers.mean(dg_loss)


	 ...

	 generated_img = exe.run(g_program,
                                    feed={'noise': n},
                                    fetch_list={g_img})[0]

      real_data = numpy.array([x[0] for x in data]).astype('float32')
            real_data = real_data.reshape(num_true, 784)
            total_data = numpy.concatenate([real_data, generated_img])
            total_label = numpy.concatenate([
                numpy.ones(
                    shape=[real_data.shape[0], 1], dtype='float32'),
                numpy.zeros(
                    shape=[real_data.shape[0], 1], dtype='float32')
            ])
            d_loss_np = exe.run(d_program,
                                feed={'img': total_data,
                                      'label': total_label},
                                fetch_list={d_loss})[0]                              
```

完整代码请参考：https://github.com/PaddlePaddle/Paddle/blob/6c80bb3ce964f1b6271ffad1d9614e93e0882c1d/python/paddle/fluid/tests/demo/fc_gan.py

## `待审核`2.问题：Fluid可以在模型间共享参数吗

+ 问题描述：Fluid版本的PaddlePaddle似乎没有提供接口实现模型间的参数共享，请问Fluid是否可以实现这种功能？

+ 问题分析：所谓模型间共享参数，其实就是不同的节点间使用相同的值，来实现权重共享，一个简单的方法就是不同的节点使用相同的节点名，这样在训练时，同名节点其参数其实就共享了，这种tick还是比较常见的。

+ 解决方法：

将相应layer的参数名设置成相同的名称，实现模型结构件的参数共享

```python
import paddle.fluid as fluid

fc1 = fluid.layers.fc(
    input=input1,
    param_attr=fluid.param_attr.ParamAttr(name='fc.w'),
    bias_attr=fluid.param_attr.ParamAttr(name='fc.b'))

fc2 = fluid.layers.fc(
    input=input2,
    param_attr=fluid.param_attr.ParamAttr(name='fc.w'),
    bias_attr=fluid.param_attr.ParamAttr(name='fc.b'))
```

## `待审核`3.问题：Fluid版多卡环境如何进行训练？

+ 问题描述：物理机有多个GPU设备，Fluid是否支持使用多卡同时进行训练？

+ 问题解答：

在Fluid版的Paddle中，可以使用paddle.fluid.ParallelExecutor()方法或 parallel_do()来实现多卡模式，而常见的Executor只能支持单卡模式，所以如果直接Executor会报出相应的错误。

parallel_do 会负责数据的切分，在多个设备上并行地执行一段相同的计算，最后合并计算结果。而ParallelExecutor的功能也是近似的。


ParallelExecutor使用实例代码如下：

```python
pe = fluid.ParallelExecutor(use_cuda=use_cuda,
                            loss_name=avg_cost.name,
                            main_program=fluid.default_main_program())
loss = pe.run(feed=feeder.feed(cur_batch),
              fetch_list=[avg_cost.name]))
```

ParallelExecutor更多内容可以参考：http://paddlepaddle.org/documentation/docs/zh/1.2/api_cn/fluid_cn.html#parallelexecutor


+ 问题拓展：

parallel_do 的原理示意图如下：

![](https://raw.githubusercontent.com/ayuLiao/images/master/paddle_do.png)

parallel_do使用例子可以参考https://mp.weixin.qq.com/s/6xU0cmg1biH4c-mmwbkjNg


## `待审核`4.问题：在训练前，加载预训练模型的接口问题

+ 问题描述：在参考Fluid版图像分类代码时，发现加载与训练模型同时使用了load_persistabels和load_vas，两者有什么区别？

+ 相关代码：

```
if checkpoint is not None:
        #使用load_persistables方法
        fluid.io.load_persistables(exe, checkpoint, main_program=train_prog)

...

if pretrained_model:

        def if_exist(var):
            return os.path.exists(os.path.join(pretrained_model, var.name))
        # 使用load_vars方法
        fluid.io.load_vars(
            exe, pretrained_model, main_program=train_prog, predicate=if_exist)
```

+ 问题解答：
Fluid版的Paddle中，vars可以看作是包含params和persistables的，也即是load_vars加载vars其实可以理解成即加载params又家具persistables，而加载checkpoint使用load_persistabels方法则可，常见的使用情景就是训练到了一半，程序挂了，需要继续训练。

+ 问题拓展：
Fluid版中还保留这load_params方法，使用load_params同样可以加载预训练模型，关于load_params更多内容，可以参考:http://paddlepaddle.org/documentation/api/zh/1.1/io.html#load-params


## `待审核`5.问题：Fluid中如何分别优化多个网络结构？

+ 问题描述：如何使用PaddlePaddle分辨优化不同的网络结构？我参考了官方代码，但大部分都是定义optimizer_program()方法，方法中就调用一个优化器对网络进行优化

+ 相关代码：

```
def optimizer_program():
    return fluid.optimizer.Adam(learning_rate=0.001)
```


+ 问题分析：

Fluid版的Paddle提供多种优化器，如常见的SGD、Adam等，其背后都是对应的优化算法，而目前主流的优化算法都是梯度下降优化模型权重值的思想，理解了这一点，那么要实现优化多个网络结构，就需要将不同网络结构的参数节点提取出来，分别对这些节点集合使用优化算法来优化，从而达到分别优化不同网络的需求。

+ 解决方法：

要分别优化不同的网络，常见的做法就是不同的网络结构中，不同的结构有对应的命名，这些命名都是有一定规则的，然后通过这些节点的命名就可以找出这些节点，从而实现分别优化，实例代码如下：

```
g_program = dg_program.clone()

opt.minimize(
        loss=dg_loss,
        startup_program=startup_program,
        parameter_list=[
            p.name for p in g_program.global_block().all_parameters()
        ]
    )
```

完整代码请参考：https://github.com/PaddlePaddle/Paddle/blob/6c80bb3ce964f1b6271ffad1d9614e93e0882c1d/python/paddle/fluid/tests/demo/fc_gan.py


## `待审核`6.问题：feed_order相关的问题

+ 问题描述：feed_order与构建的模型之间存在什么关系？

+ 报错输出：

```
Traceback (most recent call last):
  File "/Users/ayuliao/Desktop/Paddle/Paddlecode/code2.py", line 116, in <module>
    feed_order=['label', 'pixel']
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 405, in train
    feed_order)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 483, in _train_by_executor
    self._train_by_any_executor(event_handler, exe, num_epochs, reader)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 496, in _train_by_any_executor
    for step_id, data in enumerate(reader()):
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 277, in __reader_creator__
    yield self.feed(item)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 198, in feed
    ret_dict[each_name] = each_converter.done()
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 75, in done
    arr = arr.reshape(self.shape)
ValueError: cannot reshape array of size 128 into shape (3,32,32)
```


+ 相关代码：

```python
# 调用网络，获得预测结构
def inference_program():
    images = fluid.layers.data(name='pixel', shape=[3, 32, 32], dtype='float32')
    predict = vgg_bn_drop(images)
    return predict


def train_program():
    predict = inference_program() #预测值
    label = fluid.layers.data(name='label', shape=[1], dtype='int64')
    cost = fluid.layers.cross_entropy(input=predict, label=label)
    avg_cost = fluid.layers.mean(cost)
    accuracy = fluid.layers.accuracy(input=predict, label=label)
    return [avg_cost, accuracy]

...

trainer.train(
    reader=train_reader,
    num_epochs=2,
    event_handler=event_handler_plot,
    feed_order=['label', 'pixel']
)
```


+ 问题分析：

从报错输出可以看出，应该是对feed_order理解不够全面

当前Fliud版本中有两种常见的训练模式，一种是定义训练器trainer，另一种是定义执行器Executor，这两种方式在传参方面有些不同，其中Executor相对清晰一些，输入的数据对应着模型输入层的名称，实例代码如下：

```python
x = fluid.layers.data(name="x",shape=[1],dtype='float32')
y = fluid.layers.data(name="y",shape=[1],dtype='float32')

outs = exe.run(
        feed={'x':train_data,'y':y_true},
        fetch_list=[y_predict.name,avg_cost.name])
```

而trainer训练器通过feed_order来实现相同的功能，即输入数据要对应上模型中不同的输入层。这里没有那么直观，要求是feed_order定义输入数据的训练对应上模型中相应顺序的输入层，即输入数据被那一层处理有feed_order定义。

+ 解决方法：

调整feed_order定义的顺序，具体的顺序与真实的输入数据的顺序相关。

代码如下：

```
trainer.train(
    reader=train_reader,
    num_epochs=2,
    event_handler=event_handler_plot,
    feed_order=['pixel', 'label']
)
```

在使用Fluid进行数据训练前，可以使用numpy等库查看输入数据的形状。






