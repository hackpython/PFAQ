# 模型训练

## `已审核`1.问题：Fluid接口是否可以同时训练2个不同的网络

+ 问题描述：我是否可以使用Fluid版本的PaddlePaddle实现同时训练2个不同的网络

+ 问题解答：
这是可以的，同时训练2个不同的网络是比较常见的需求，Fluid可以请求实现这个需求，简单而言你只需要定义两个网络结构，然后调用执行器分别执行这两个网络这可。

+ 解决方法：

这里定义简单的GAN来实现同时训练2个不同的网络，部分代码如下：

```
def D(x):
    hidden = fluid.layers.fc(input=x,
                             size=200,
                             act='relu',
                             param_attr='D.w1',
                             bias_attr='D.b1')
    logits = fluid.layers.fc(input=hidden,
                             size=1,
                             act=None,
                             param_attr='D.w2',
                             bias_attr='D.b2')
    return logits


def G(x):
    hidden = fluid.layers.fc(input=x,
                             size=200,
                             act='relu',
                             param_attr='G.w1',
                             bias_attr='G.b1')
    img = fluid.layers.fc(input=hidden,
                          size=28 * 28,
                          act='tanh',
                          param_attr='G.w2',
                          bias_attr='G.b2')
    return img


def main():
	 ...

	 with fluid.program_guard(dg_program, startup_program):
	    noise = fluid.layers.data(
	        name='noise', shape=[NOISE_SIZE], dtype='float32')
	    g_img = G(x=noise)
	    g_program = dg_program.clone()
	    dg_loss = fluid.layers.sigmoid_cross_entropy_with_logits(
	        x=D(g_img),
	        label=fluid.layers.fill_constant_batch_size_like(
	            input=noise, dtype='float32', shape=[-1, 1], value=1.0))
	    dg_loss = fluid.layers.mean(dg_loss)


	 ...

	 generated_img = exe.run(g_program,
                                    feed={'noise': n},
                                    fetch_list={g_img})[0]

      real_data = numpy.array([x[0] for x in data]).astype('float32')
            real_data = real_data.reshape(num_true, 784)
            total_data = numpy.concatenate([real_data, generated_img])
            total_label = numpy.concatenate([
                numpy.ones(
                    shape=[real_data.shape[0], 1], dtype='float32'),
                numpy.zeros(
                    shape=[real_data.shape[0], 1], dtype='float32')
            ])
            d_loss_np = exe.run(d_program,
                                feed={'img': total_data,
                                      'label': total_label},
                                fetch_list={d_loss})[0]                              
```

完整代码请参考：https://github.com/PaddlePaddle/Paddle/blob/6c80bb3ce964f1b6271ffad1d9614e93e0882c1d/python/paddle/fluid/tests/demo/fc_gan.py

## `已审核`2.问题：Fluid可以在模型间共享参数吗

+ 问题描述：Fluid版本的PaddlePaddle似乎没有提供接口实现模型间的参数共享，请问Fluid是否可以实现这种功能？

+ 问题分析：所谓模型间共享参数，其实就是不同的节点间使用相同的值，来实现权重共享，一个简单的方法就是不同的节点使用相同的节点名，这样在训练时，同名节点其参数其实就共享了，这种tick还是比较常见的。

+ 解决方法：

将相应layer的参数名设置成相同的名称，实现模型结构件的参数共享

```python
import paddle.fluid as fluid

fc1 = fluid.layers.fc(
    input=input1,
    param_attr=fluid.param_attr.ParamAttr(name='fc.w'),
    bias_attr=fluid.param_attr.ParamAttr(name='fc.b'))

fc2 = fluid.layers.fc(
    input=input2,
    param_attr=fluid.param_attr.ParamAttr(name='fc.w'),
    bias_attr=fluid.param_attr.ParamAttr(name='fc.b'))
```

## `已审核`3.问题：Fluid版多卡环境如何进行训练？

+ 问题描述：物理机有多个GPU设备，Fluid是否支持使用多卡同时进行训练？

+ 问题解答：

在Fluid版的Paddle中，可以使用paddle.fluid.ParallelExecutor()方法或 parallel_do()来实现多卡模式，而常见的Executor只能支持单卡模式，所以如果直接Executor会报出相应的错误。

parallel_do 会负责数据的切分，在多个设备上并行地执行一段相同的计算，最后合并计算结果。而ParallelExecutor的功能也是近似的。


ParallelExecutor使用实例代码如下：

```python
pe = fluid.ParallelExecutor(use_cuda=use_cuda,
                            loss_name=avg_cost.name,
                            main_program=fluid.default_main_program())
loss = pe.run(feed=feeder.feed(cur_batch),
              fetch_list=[avg_cost.name]))
```

ParallelExecutor更多内容可以参考：http://paddlepaddle.org/documentation/docs/zh/1.2/api_cn/fluid_cn.html#parallelexecutor


+ 问题拓展：

parallel_do 的原理示意图如下：

![](https://raw.githubusercontent.com/ayuLiao/images/master/paddle_do.png)

parallel_do使用例子可以参考https://mp.weixin.qq.com/s/6xU0cmg1biH4c-mmwbkjNg


## `已审核`4.问题：在训练前，加载预训练模型的接口问题

+ 问题描述：在参考Fluid版图像分类代码时，发现加载与训练模型同时使用了load_persistabels和load_vas，两者有什么区别？

+ 相关代码：

```
if checkpoint is not None:
        #使用load_persistables方法
        fluid.io.load_persistables(exe, checkpoint, main_program=train_prog)

...

if pretrained_model:

        def if_exist(var):
            return os.path.exists(os.path.join(pretrained_model, var.name))
        # 使用load_vars方法
        fluid.io.load_vars(
            exe, pretrained_model, main_program=train_prog, predicate=if_exist)
```

+ 问题解答：
Fluid版的Paddle中，vars可以看作是包含params和persistables的，也即是load_vars加载vars其实可以理解成即加载params又家具persistables，而加载checkpoint使用load_persistabels方法则可，常见的使用情景就是训练到了一半，程序挂了，需要继续训练。

+ 问题拓展：
Fluid版中还保留这load_params方法，使用load_params同样可以加载预训练模型，关于load_params更多内容，可以参考:http://paddlepaddle.org/documentation/api/zh/1.1/io.html#load-params


## `已审核`5.问题：Fluid中如何分别优化多个网络结构？

+ 问题描述：如何使用PaddlePaddle分辨优化不同的网络结构？我参考了官方代码，但大部分都是定义optimizer_program()方法，方法中就调用一个优化器对网络进行优化

+ 相关代码：

```
def optimizer_program():
    return fluid.optimizer.Adam(learning_rate=0.001)
```


+ 问题分析：

Fluid版的Paddle提供多种优化器，如常见的SGD、Adam等，其背后都是对应的优化算法，而目前主流的优化算法都是梯度下降优化模型权重值的思想，理解了这一点，那么要实现优化多个网络结构，就需要将不同网络结构的参数节点提取出来，分别对这些节点集合使用优化算法来优化，从而达到分别优化不同网络的需求。

+ 解决方法：

要分别优化不同的网络，常见的做法就是不同的网络结构中，不同的结构有对应的命名，这些命名都是有一定规则的，然后通过这些节点的命名就可以找出这些节点，从而实现分别优化，实例代码如下：

```
g_program = dg_program.clone()

opt.minimize(
        loss=dg_loss,
        startup_program=startup_program,
        parameter_list=[
            p.name for p in g_program.global_block().all_parameters()
        ]
    )
```

完整代码请参考：https://github.com/PaddlePaddle/Paddle/blob/6c80bb3ce964f1b6271ffad1d9614e93e0882c1d/python/paddle/fluid/tests/demo/fc_gan.py


## `已审核`6.问题：feed_order相关的问题

+ 问题描述：feed_order与构建的模型之间存在什么关系？

+ 报错输出：

```
Traceback (most recent call last):
  File "/Users/ayuliao/Desktop/Paddle/Paddlecode/code2.py", line 116, in <module>
    feed_order=['label', 'pixel']
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 405, in train
    feed_order)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 483, in _train_by_executor
    self._train_by_any_executor(event_handler, exe, num_epochs, reader)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/contrib/trainer.py", line 496, in _train_by_any_executor
    for step_id, data in enumerate(reader()):
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 277, in __reader_creator__
    yield self.feed(item)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 198, in feed
    ret_dict[each_name] = each_converter.done()
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/data_feeder.py", line 75, in done
    arr = arr.reshape(self.shape)
ValueError: cannot reshape array of size 128 into shape (3,32,32)
```


+ 相关代码：

```python
# 调用网络，获得预测结构
def inference_program():
    images = fluid.layers.data(name='pixel', shape=[3, 32, 32], dtype='float32')
    predict = vgg_bn_drop(images)
    return predict


def train_program():
    predict = inference_program() #预测值
    label = fluid.layers.data(name='label', shape=[1], dtype='int64')
    cost = fluid.layers.cross_entropy(input=predict, label=label)
    avg_cost = fluid.layers.mean(cost)
    accuracy = fluid.layers.accuracy(input=predict, label=label)
    return [avg_cost, accuracy]

...

trainer.train(
    reader=train_reader,
    num_epochs=2,
    event_handler=event_handler_plot,
    feed_order=['label', 'pixel']
)
```


+ 问题分析：

从报错输出可以看出，应该是对feed_order理解不够全面

当前Fliud版本中有两种常见的训练模式，一种是定义训练器trainer，另一种是定义执行器Executor，这两种方式在传参方面有些不同，其中Executor相对清晰一些，输入的数据对应着模型输入层的名称，实例代码如下：

```python
x = fluid.layers.data(name="x",shape=[1],dtype='float32')
y = fluid.layers.data(name="y",shape=[1],dtype='float32')

outs = exe.run(
        feed={'x':train_data,'y':y_true},
        fetch_list=[y_predict.name,avg_cost.name])
```

而trainer训练器通过feed_order来实现相同的功能，即输入数据要对应上模型中不同的输入层。这里没有那么直观，要求是feed_order定义输入数据的训练对应上模型中相应顺序的输入层，即输入数据被那一层处理有feed_order定义。

+ 解决方法：

调整feed_order定义的顺序，具体的顺序与真实的输入数据的顺序相关。

代码如下：

```
trainer.train(
    reader=train_reader,
    num_epochs=2,
    event_handler=event_handler_plot,
    feed_order=['pixel', 'label']
)
```

在使用Fluid进行数据训练前，可以使用numpy等库查看输入数据的形状。

## `待审核`7.问题：paddle训练速度慢，主要是数据传输慢，怎么解决？

+ 问题描述：单机2个GPU跑二分类，特征7k维，batch_size=1024，网络结构是一个2层的CNN，参数维数比较低。
使用profiler分析发现耗时应该主要是数据从cpu到gpu拷贝比较慢，如何解决？

+ 问题分析：
GPU模式下，在模型比较复杂时，GUP的利用率会比较高，此时训练的速度是比较快的，但是依旧还是要利用cpu将数据拷贝到GPU，这一步会占用一定的时间，这个难以避免。

+ 解决方法：

使用py_reader接口以异步方式读取数据，从而加快数据读取方面的处理，但是当前Fluid版提供的py_reader接口使用的是双buffer的策略，即通过尽量减少python预处理所占用的时间来提高数据读取的速度，但依旧无法做到数据拷贝和GPU计算overlap。

如果模型比较简单，建议可以直接使用CPU运行，减少了数据从CPU拷贝到GPU这一步的耗时。

## `待审核`8.问题：Fluid训练时，使用profile分析性能对训练速度影响大吗？是否有相关数据？ 

+ 问题描述：服务端有其他服务，使用Fluid训练时，先验证是否会对其他服务造成较大的影响，即进行性能分析，如ResponseTime(RT)分析等

+ 问题分析：
使用Fluid进行训练时，通常会占用一定的CPU、GPU等硬件资源，如果原本的服务会使用这些资源，那么对原本的服务是会造成一定的影响的，通常建议将Fluid训练逻辑与具体服务分离到不同的物理设备上，当训练完成获得对应的模型文件后，再使用模型文件来提升现有的业务，如果需要实时训练，建议通过网络传输的形式，将数据传到训练设备上，进行训练。

+ 问题解答：
目前暂时没有相关的数据，不建议在训练的同时进行profile性能分析。如需profile可以使用少量数据单独进行测试。

## `待审核`9.问题：不使用clone()方法，不同的模型为何可以共享参数

+ 问题描述：阅读了Fluid API的文档，其中对clone()方法的描述有疑惑，clone()方法用于克隆一个program，使得克隆的program具有与被克隆的program有相同结构，但其中的代码示例二说分别运行 train Program 和 test Program，则可以不使用clone，test_program是怎么拿到train_program的参数的呢？

+ 相关代码：

如果分别运行 train Program 和 test Program，则可以不使用clone。

```python
import paddle.fluid as fluid

def network(is_test):
     img = fluid.layers.data(name='image', shape=[784])
     hidden = fluid.layers.fc(input=img, size=200, act='relu')
     hidden = fluid.layers.dropout(hidden, dropout_prob=0.5, is_test=is_test)
     loss = fluid.layers.cross_entropy(
                 input=fluid.layers.fc(hidden, size=10, act='softmax'),
                 label=fluid.layers.data(name='label', shape=[1], dtype='int64'))
     return loss

 train_program = fluid.Program()
 startup_program = fluid.Program()
 test_program = fluid.Program()

 with fluid.program_guard(train_program, startup_program):
     with fluid.unique_name.guard():
         loss = network(is_test=False)
         sgd = fluid.optimizer.SGD(learning_rate=1e-3)
         sgd.minimize(loss)

 # 不使用测试阶段的startup program
 with fluid.program_guard(test_program, fluid.Program()):
     with fluid.unique_name.guard():
         loss = network(is_test=True)
```

+ 问题分析：

通常，用户编写的程序都会转成相应的block域program，用户描述的block与program信息在Fluid中以protobuf 格式保存，所有的protobub信息被定义在framework.proto中，在Fluid中被称为BlockDesc和ProgramDesc。ProgramDesc和BlockDesc的概念类似于一个抽象语法树。

如果两个Program都在同一个ProgramDesc中，那么是可以共享其中的参数的。

+ 问题解答：
train_program, test_program都是fluid.Program()，因此都在一个ProgramDesc里面，关键代码为：

```python
train_program = fluid.Program()
startup_program = fluid.Program()
test_program = fluid.Program()
```


## `待审核`10.问题：在Windows上加载合并模型报错

+ 问题描述：使用paddlepaddle 1.2.0在windows10上使用保存的模型进行预测，在Ubunut下使用GPU训练，然后使用保存预测模型接口paddle.fluid.io.save_inference_model保存训练的模型，然后再Windows上通过调用paddle.fluid.io.load_inference_model接口加载模型，报出错误

+ 报错输出：

```bash
  File "C:\Python35\lib\site-packages\paddle\fluid\io.py", line 784, in load_inference_model
    load_persistables(executor, dirname, program, params_filename)
  File "C:\Python35\lib\site-packages\paddle\fluid\io.py", line 529, in load_persistables
    filename=filename)
  File "C:\Python35\lib\site-packages\paddle\fluid\io.py", line 395, in load_vars
    filename=filename)
  File "C:\Python35\lib\site-packages\paddle\fluid\io.py", line 436, in load_vars
    executor.run(load_prog)
  File "C:\Python35\lib\site-packages\paddle\fluid\executor.py", line 472, in run
    self.executor.run(program.desc, scope, 0, True, True)
paddle.fluid.core.EnforceNotMet: Cannot read more from file ./model\params at [E:\dist\Paddle\paddle\fluid\operators\load_combine_op.cc:58]
PaddlePaddle Call Stacks: 
Windows not support stack backtrace yet.
```

+ 问题分析：
从报错信息中发现`Windows not support stack backtrace yet.`，表示使用的功能还暂不支持，Fluid1.2目前在windows上还暂不支持callback trace。

+ 解决方法：
从问题描述中可知，模型在ubuntu中使用GPU进行训练，然后再windows下对训练好的模型进行加载，此时因为windows暂不支持callback trace功能导致加载模型时报错，请尝试在linux下加载使用保存的模型。

## `待审核`11.问题：使用Fluid时，发现使用layers.embedding的时候，设置is_sparse=True 比 is_sparse=False 还慢很多。

+ 问题描述：使用Fluid时，发现使用layers.embedding的时候，设置is_sparse=True 比 is_sparse=False 还慢很多。

+ 相关代码：

```python
import paddle
import paddle.fluid as fluid
from paddle.fluid import layers
from paddle.fluid.param_attr import ParamAttr
import numpy as np
import time

def fluid_create_lod_tensor(array, lod, place):
    tensor = fluid.LoDTensor()
    tensor.set(np.array(array), place)
    tensor.set_lod(lod)
    return tensor

def net():
    x = layers.data(name='x', shape=[-1, 1], dtype='int64')
    xavier_initializer = fluid.initializer.Xavier()
    param_clip = fluid.clip.GradientClipByValue(1.0)
    embed = layers.embedding(x,
                    size=[1000000, 16],
                    param_attr=ParamAttr(name='embed',
                                        initializer=xavier_initializer,
                                        gradient_clip=param_clip
                                        ),
                    is_sparse=False)
                    # is_sparse=True)
    out = layers.fc(embed, size=1)
    loss = layers.reduce_mean(layers.square(out))
    opt = fluid.optimizer.AdamOptimizer(
        learning_rate=0.01, beta1=0.9, beta2=0.999)
    opt.minimize(loss)
    return loss

                                
def train():
    myprogram = fluid.Program()
    with fluid.program_guard(myprogram):
        out = net()
    test_program = myprogram.clone(for_test=True)
    
    place = fluid.CPUPlace()
    exe = fluid.Executor(place)
    exe.run(fluid.default_startup_program())

    # data
    x_data = np.ones([10, 1]).astype('int64')
    x_lod = []
    x_tensor = fluid_create_lod_tensor(x_data, x_lod, place)

    time_list = []
    for _ in range(10):
        s = time.time()
        results = exe.run(myprogram, feed={'x': x_tensor}, fetch_list=[out])
        time_list.append(time.time() - s)
    print ('time', np.mean(time_list))

                                
if __name__ == "__main__":
    train()
```

+ 问题分析：

从代码中看到使用了Adam优化方法，当前Adam操作会进行如下操作：

1.先将 Sparse 的 Tensor 转换为 Dense 的 Tensor;
2.针对Embedding表的所有字段都进行更新动量的计算以达到数学上正确的结果;

+ 解决方法：

将Adam优化器换成SGD优化器，看看是否提速。

## `待审核` 12. Fluid训练模型时，出现Enforce failed

+ 问题描述：通过Fluid构建好模型结构后，进行训练，代码参考了Paddlemodel中提供的代码，修改了部分网络结构后，运行代码报错

+ 报错输出：

```
Traceback (most recent call last):
  File "train.py", line 309, in <module>
    train()
  File "train.py", line 165, in train
    rnn_model=rnn_model)
  File "/Users/ayuliao/Desktop/Paddle/models/fluid/PaddleNLP/language_model/lstm/lm_model.py", line 295, in lm_model
    logits=projection, label=y, soft_label=False)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layers/nn.py", line 4746, in softmax_with_cross_entropy
    'ignore_index': ignore_index})
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/layer_helper.py", line 50, in append_op
    return self.main_program.current_block().append_op(*args, **kwargs)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/framework.py", line 1207, in append_op
    op = Operator(block=self, desc=op_desc, *args, **kwargs)
  File "/Users/ayuliao/anaconda3/envs/paddle/lib/python3.5/site-packages/paddle/fluid/framework.py", line 656, in __init__
    self.desc.infer_shape(self.block.desc)
paddle.fluid.core.EnforceNotMet: Enforce failed. Expected logits_dims.size() == 2UL, but received logits_dims.size():3 != 2UL:2.
The input of softmax_with_cross_entropy should be a 2-D tensor. at [/Users/paddle/minqiyang/Paddle/paddle/fluid/operators/softmax_with_cross_entropy_op.cc:104]
PaddlePaddle Call Stacks:
0          0x10debca68p paddle::platform::EnforceNotMet::EnforceNotMet(std::exception_ptr, char const*, int) + 760
1          0x10ea9c476p paddle::operators::SoftmaxWithCrossEntropyOp::InferShape(paddle::framework::InferShapeContext*) const + 3110
2          0x10df79e68p paddle::framework::OpDesc::InferShape(paddle::framework::BlockDesc const&) const + 1496
3          0x10df43479p _ZZN8pybind1112cpp_function10initializeIZNS0_C1IvN6paddle9framework6OpDescEJRKNS4_9BlockDescEEJNS_4nameENS_9is_methodENS_7siblingEEEEMT0_KFT_DpT1_EDpRKT2_EUlPKS5_S8_E_vJSN_S8_EJS9_SA_SB_EEEvOSD_PFSC_SF_ESL_ENKUlRNS_6detail13function_callEE_clESU_ + 185
4          0x10dec73aap pybind11::cpp_function::dispatcher(_object*, _object*, _object*) + 5786
5          0x10115359fp PyCFunction_Call + 127
6          0x10121e7e7p PyEval_EvalFrameEx + 33207
7          0x101214fafp _PyEval_EvalCodeWithName + 335
8          0x1011206aap function_call + 106
9          0x1010dcb35p PyObject_Call + 69
10         0x1010ff694p method_call + 148
11         0x1010dcb35p PyObject_Call + 69
12         0x101179415p slot_tp_init + 117
13         0x10117dac1p type_call + 209
14         0x1010dcb35p PyObject_Call + 69
15         0x10121bc9bp PyEval_EvalFrameEx + 22123
16         0x101214fafp _PyEval_EvalCodeWithName + 335
17         0x1011206aap function_call + 106
18         0x1010dcb35p PyObject_Call + 69
19         0x10121bc9bp PyEval_EvalFrameEx + 22123
20         0x101214fafp _PyEval_EvalCodeWithName + 335
21         0x10121b2a7p PyEval_EvalFrameEx + 19575
22         0x101214fafp _PyEval_EvalCodeWithName + 335
23         0x10121b2a7p PyEval_EvalFrameEx + 19575
24         0x101214fafp _PyEval_EvalCodeWithName + 335
25         0x10121b2a7p PyEval_EvalFrameEx + 19575
26         0x101214fafp _PyEval_EvalCodeWithName + 335
27         0x10121b2a7p PyEval_EvalFrameEx + 19575
28         0x101214fafp _PyEval_EvalCodeWithName + 335
29         0x101267758p PyRun_FileExFlags + 248
30         0x101266eeep PyRun_SimpleFileExFlags + 382
31         0x10128bd86p Py_Main + 3622
32         0x1010cd861p main + 497
33      0x7fff75c56015p start + 1
34                 0x8p
```

+ 相关代码：

```python
rnn_out = layers.reshape(rnn_out, shape=[-1, num_steps, hidden_size])


softmax_weight = layers.create_parameter([hidden_size, vocab_size], dtype="float32", name="softmax_weight", \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
softmax_bias = layers.create_parameter([vocab_size], dtype="float32", name='softmax_bias', \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))

projection = layers.matmul(rnn_out, softmax_weight)
projection = layers.elementwise_add(projection, softmax_bias)

loss = layers.softmax_with_cross_entropy(
    logits=projection, label=y, soft_label=False)
```

+ 问题分析：

从错误栈中可以看到`Enforce failed. Expected logits_dims.size() == 2UL, but received logits_dims.size():3 != 2UL:2.`报错，该报错说明模型的结构存在错误


+ 解决方法：

```python
rnn_out = layers.reshape(rnn_out, shape=[-1, num_steps, hidden_size])


softmax_weight = layers.create_parameter([hidden_size, vocab_size], dtype="float32", name="softmax_weight", \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))
softmax_bias = layers.create_parameter([vocab_size], dtype="float32", name='softmax_bias', \
        default_initializer=fluid.initializer.UniformInitializer(low=-init_scale, high=init_scale))

projection = layers.matmul(rnn_out, softmax_weight)
projection = layers.elementwise_add(projection, softmax_bias)

projection = layers.reshape(projection, shape=[-1, vocab_size])

loss = layers.softmax_with_cross_entropy(
    logits=projection, label=y, soft_label=False)
```










